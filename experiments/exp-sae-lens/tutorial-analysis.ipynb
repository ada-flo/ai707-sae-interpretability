{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54b5ae3d",
   "metadata": {},
   "source": [
    "## Imports & Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35b20600",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ssd/jdh/interpretability/experiments/exp-sae-lens/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/ssd/jdh/interpretability/experiments/exp-sae-lens/.venv/lib/python3.10/site-packages/sae_lens/saes/sae.py:248: UserWarning: \n",
      "This SAE has non-empty model_from_pretrained_kwargs. \n",
      "For optimal performance, load the model like so:\n",
      "model = HookedSAETransformer.from_pretrained_no_processing(..., **cfg.model_from_pretrained_kwargs)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sae_lens import SAE\n",
    "\n",
    "sae = SAE.from_pretrained(\n",
    "    release = \"gpt2-small-res-jb\", # see other options in sae_lens/pretrained_saes.yaml\n",
    "    sae_id = \"blocks.8.hook_resid_pre\", # won't always be a hook point\n",
    "    device = \"cuda\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51dc2612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa82fba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for displaying vis in Colab / notebook\n",
    "import webbrowser\n",
    "import http.server\n",
    "import socketserver\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25e64e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLAB = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86506101",
   "metadata": {},
   "source": [
    "## Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8be39fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e23ae02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_vis_inline(filename: str, height: int = 850):\n",
    "    \"\"\"\n",
    "    Displays the HTML files in Colab. Uses global `PORT` variable defined in prev cell, so that each\n",
    "    vis has a unique port without having to define a port within the function.\n",
    "    \"\"\"\n",
    "    if not (COLAB):\n",
    "        webbrowser.open(filename)\n",
    "\n",
    "    else:\n",
    "        global PORT\n",
    "\n",
    "        def serve(directory):\n",
    "            os.chdir(directory)\n",
    "\n",
    "            # Create a handler for serving files\n",
    "            handler = http.server.SimpleHTTPRequestHandler\n",
    "\n",
    "            # Create a socket server with the handler\n",
    "            with socketserver.TCPServer((\"\", PORT), handler) as httpd:\n",
    "                print(f\"Serving files from {directory} on port {PORT}\")\n",
    "                httpd.serve_forever()\n",
    "\n",
    "        thread = threading.Thread(target=serve, args=(\"/content\",))\n",
    "        thread.start()\n",
    "\n",
    "        output.serve_kernel_port_as_iframe(\n",
    "            PORT, path=f\"/{filename}\", height=height, cache_in_notebook=True\n",
    "        )\n",
    "\n",
    "        PORT += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f81dba2",
   "metadata": {},
   "source": [
    "# Loading a pretrained Sparse Autoencoder\n",
    "\n",
    "Below we load a Transformerlens model, a pretrained SAE and a dataset from huggingface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f9d40d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformer_lens import HookedTransformer\n",
    "from sae_lens import SAE\n",
    "\n",
    "model = HookedTransformer.from_pretrained(\"gpt2-small\", device=device)\n",
    "\n",
    "# the cfg dict is returned alongside the SAE since it may contain useful information for analysing the SAE (eg: instantiating an activation store)\n",
    "# Note that this is not the same as the SAEs config dict, rather it is whatever was in the HF repo, from which we can extract the SAE config dict\n",
    "# We also return the feature sparsities which are stored in HF for convenience.\n",
    "sae = SAE.from_pretrained(\n",
    "    release=\"gpt2-small-res-jb\",  # see other options in sae_lens/pretrained_saes.yaml\n",
    "    sae_id=\"blocks.8.hook_resid_pre\",  # won't always be a hook point\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a6e0c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_lens.utils import tokenize_and_concatenate\n",
    "\n",
    "dataset = load_dataset(\n",
    "    path=\"NeelNanda/pile-10k\",\n",
    "    split=\"train\",\n",
    "    streaming=False,\n",
    ")\n",
    "\n",
    "# (1) Tokenization: Converts raw text into token IDs\n",
    "# (2) Concatenation: Combines token IDs into a single tensor (one massive long stream of tokens)\n",
    "# (3) Chunking: Splits the tensor into smaller chunks\n",
    "\n",
    "token_dataset = tokenize_and_concatenate(\n",
    "    dataset=dataset,  # type: ignore\n",
    "    tokenizer=model.tokenizer,  # type: ignore\n",
    "    streaming=True,\n",
    "    max_length=sae.cfg.metadata.context_size,\n",
    "    add_bos_token=sae.cfg.metadata.prepend_bos,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b617c703",
   "metadata": {},
   "source": [
    "## Basic Analysis\n",
    "\n",
    "Let's check some basic stats on this SAE in order to see how some basic functionality in the codebase works.\n",
    "\n",
    "We'll calculate:\n",
    "\n",
    "- L0 (the number of features that fire per activation)\n",
    "    - Refers to the number of non-zero features that are active for a given input.\n",
    "    - Sparsity Metric: It is the primary way to measure \"sparsity.\" \n",
    "    - \"Features that Fire\": When the code calculates L0, it is counting how many features have an activation value greater than zero.\n",
    "    - An SAE has thousands of possible features (e.g., 32,768), but for any single token (like the word \" the\"), only a tiny handful should be active to represent it.\n",
    "    - Interpretation:\n",
    "        - A high L0 value indicates that many features are active, which can be a sign of overfitting or noise.\n",
    "        - A low L0 value indicates that only a few features are active, which is a sign of sparsity.\n",
    "- The cross entropy loss when the output of the SAE is used in place of the activations.\n",
    "    - The Baseline (Original Loss): Use the model normally. It processes the text and tries to predict the next token. If it is a good model, it assigns high probability to the correct next token, resulting in low Cross Entropy Loss.\n",
    "    - The Intervention (Reconstruction Loss): \n",
    "        - Take the internal activations (what the model is \"thinking\" at a specific layer).\n",
    "        - Pass them through the SAE (Compression -> Sparse Features -> Decompression).\n",
    "        - Swap the original activations with the SAE's imperfect reconstructed versions.\n",
    "        - Force the model to continue computing using this reconstructed data.\n",
    "    - The Comparison\n",
    "        - If the Reconstruction Loss is effectively the same as the Original Loss, it means the SAE successfully preserved all the \"important\" information the model needed to predict the next token.\n",
    "        - If the Loss spikes (gets much higher), it means the SAE \"broke\" the model's chain of thought, implying it failed to capture critical features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0effa25a",
   "metadata": {},
   "source": [
    "### L0 Test and Reconstruction Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "246d0ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average l0 68.78986358642578\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "bingroup": "x",
         "hovertemplate": "Number of SAE features active per token (L0 count)=%{x}<br>count=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "histogram",
         "x": {
          "bdata": "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",
          "dtype": "f4"
         },
         "xaxis": "x",
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Distribution of SAE feature sparsity (L0)"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Number of SAE features active per token (L0 count)"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "count"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sae.eval()  # prevents error if we're expecting a dead neuron mask for who grads\n",
    "\n",
    "with torch.no_grad():\n",
    "    # activation store can give us tokens.\n",
    "    batch_tokens = token_dataset[:32][\"tokens\"]\n",
    "    _, cache = model.run_with_cache(batch_tokens, prepend_bos=True)\n",
    "\n",
    "    # Use the SAE\n",
    "    # returns a sparse list of features that activated\n",
    "    feature_acts = sae.encode(cache[sae.cfg.metadata.hook_name])\n",
    "    # turns the sparse list of features into original dense activations\n",
    "    sae_out = sae.decode(feature_acts)\n",
    "\n",
    "    # save some room\n",
    "    del cache\n",
    "\n",
    "    # ignore the bos token, get the number of features that activated in each token, averaged accross batch and position\n",
    "    # Slices the data to ignore the first token (position 0) -- First token is usually the \"BOS\" (Beginning of Sequence)\n",
    "    l0 = (feature_acts[:, 1:] > 0).float().sum(-1).detach()\n",
    "    # prints the average sparsity\n",
    "    print(\"average l0\", l0.mean().item())\n",
    "    # Draws the a graph shoing distribution of sparsity\n",
    "    l0_values = l0.flatten().cpu().numpy()\n",
    "    fig = px.histogram(\n",
    "        x=l0_values,\n",
    "        labels={\n",
    "            \"x\": \"Number of SAE features active per token (L0 count)\",\n",
    "            \"y\": \"Token positions in sampled batch\",\n",
    "        },\n",
    "        title=\"Distribution of SAE feature sparsity (L0)\",\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09eec9eb",
   "metadata": {},
   "source": [
    "Note that while the mean L0 is 64, it varies with the specific activation.\n",
    "In the histogram above, the x-axis shows the L0 count (number of non-zero SAE features per token position after dropping the BOS token) and the y-axis shows how many token positions fall into each bin.\n",
    "\n",
    "To estimate reconstruction performance, we calculate the CE loss of the model with and without the SAE being used in place of the activations. This will vary depending on the tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1527c082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orig 3.562199592590332\n",
      "reconstr 3.764155387878418\n",
      "Zero 11.146590232849121\n"
     ]
    }
   ],
   "source": [
    "from transformer_lens import utils\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "# next we want to do a reconstruction test.\n",
    "def reconstr_hook(activation, hook, sae_out):\n",
    "    return sae_out\n",
    "\n",
    "\n",
    "def zero_abl_hook(activation, hook):\n",
    "    return torch.zeros_like(activation)\n",
    "\n",
    "\n",
    "print(\"Orig\", model(batch_tokens, return_type=\"loss\").item()) # Calculates the original loss\n",
    "print(\n",
    "    \"reconstr\",\n",
    "    model.run_with_hooks(\n",
    "        batch_tokens,\n",
    "        fwd_hooks=[\n",
    "            (\n",
    "                sae.cfg.metadata.hook_name,\n",
    "                partial(reconstr_hook, sae_out=sae_out),\n",
    "            )\n",
    "        ],\n",
    "        return_type=\"loss\",\n",
    "    ).item(),\n",
    ") # Calculates the loss after reconstruction\n",
    "print(\n",
    "    \"Zero\",\n",
    "    model.run_with_hooks(\n",
    "        batch_tokens,\n",
    "        return_type=\"loss\",\n",
    "        fwd_hooks=[(sae.cfg.metadata.hook_name, zero_abl_hook)],\n",
    "    ).item(),\n",
    ") # Calculates the loss after zeroing out the activations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1606f2f8",
   "metadata": {},
   "source": [
    "## Specific Capability Test\n",
    "\n",
    "Validating model performance on specific tasks when using the reconstructed activation is quite important when studying specific tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7634c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized prompt: ['<|endoftext|>', 'When', ' John', ' and', ' Mary', ' went', ' to', ' the', ' shops', ',', ' John', ' gave', ' the', ' bag', ' to']\n",
      "Tokenized answer: [' Mary']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">        Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18.19</span><span style=\"font-weight: bold\"> Prob: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">69.93</span><span style=\"font-weight: bold\">% Token: | Mary|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m        Logit: \u001b[0m\u001b[1;36m18.19\u001b[0m\u001b[1m Prob: \u001b[0m\u001b[1;36m69.93\u001b[0m\u001b[1m% Token: | Mary|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 18.19 Prob: 69.93% Token: | Mary|\n",
      "Top 1th token. Logit: 15.82 Prob:  6.49% Token: | them|\n",
      "Top 2th token. Logit: 15.48 Prob:  4.66% Token: | the|\n",
      "Top 3th token. Logit: 14.93 Prob:  2.66% Token: | his|\n",
      "Top 4th token. Logit: 14.86 Prob:  2.49% Token: | John|\n",
      "Top 5th token. Logit: 14.12 Prob:  1.19% Token: | her|\n",
      "Top 6th token. Logit: 13.99 Prob:  1.04% Token: | their|\n",
      "Top 7th token. Logit: 13.70 Prob:  0.78% Token: | a|\n",
      "Top 8th token. Logit: 13.53 Prob:  0.66% Token: | him|\n",
      "Top 9th token. Logit: 13.39 Prob:  0.57% Token: | Mrs|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' Mary'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' Mary'\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Inference tensors cannot be saved for backward. Please do not use Tensors created in inference mode in computation tracked by autograd. To work around this, you can make a clone to get a normal tensor and use it in autograd, or use `torch.no_grad()` instead of `torch.inference_mode()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m logits, cache \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mrun_with_cache(example_prompt, prepend_bos\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m tokens \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto_tokens(example_prompt) \u001b[38;5;66;03m# Converts the string prompt into integer tokens (e.g., [50256, 1204, ...]) so passing it to the model later is faster/easier.\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m sae_out \u001b[38;5;241m=\u001b[39m \u001b[43msae\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcache\u001b[49m\u001b[43m[\u001b[49m\u001b[43msae\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhook_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Passes the specific activations from the hook point (e.g., \"Block 8\") through the SAE.\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# A function that ignores the incoming activations and blindly returns sae_out (our SAE reconstruction). Used to \"hot-swap\" the brain state.\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mreconstr_hook\u001b[39m(activations, hook, sae_out):\n",
      "File \u001b[0;32m~/interpretability/experiments/exp-sae-lens/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/interpretability/experiments/exp-sae-lens/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/interpretability/experiments/exp-sae-lens/.venv/lib/python3.10/site-packages/sae_lens/saes/sae.py:462\u001b[0m, in \u001b[0;36mSAE.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    461\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass through the SAE.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 462\u001b[0m     feature_acts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    463\u001b[0m     sae_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecode(feature_acts)\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_error_term:\n",
      "File \u001b[0;32m~/interpretability/experiments/exp-sae-lens/.venv/lib/python3.10/site-packages/sae_lens/saes/standard_sae.py:63\u001b[0m, in \u001b[0;36mStandardSAE.encode\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     61\u001b[0m sae_in \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_sae_in(x)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Compute the pre-activation values\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m hidden_pre \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_sae_acts_pre(\u001b[43msae_in\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mW_enc\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb_enc)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Apply the activation function (e.g., ReLU, depending on config)\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_sae_acts_post(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation_fn(hidden_pre))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Inference tensors cannot be saved for backward. Please do not use Tensors created in inference mode in computation tracked by autograd. To work around this, you can make a clone to get a normal tensor and use it in autograd, or use `torch.no_grad()` instead of `torch.inference_mode()`."
     ]
    }
   ],
   "source": [
    "example_prompt = \"When John and Mary went to the shops, John gave the bag to\"\n",
    "example_answer = \" Mary\" # Indirect Object Indentification (IOI) task\n",
    "utils.test_prompt(example_prompt, example_answer, model, prepend_bos=True) # What it does: Runs the standard model on this prompt and prints a report.\n",
    "\n",
    "logits, cache = model.run_with_cache(example_prompt, prepend_bos=True)\n",
    "tokens = model.to_tokens(example_prompt) # Converts the string prompt into integer tokens (e.g., [50256, 1204, ...]) so passing it to the model later is faster/easier.\n",
    "sae_out = sae(cache[sae.cfg.metadata.hook_name]) # Passes the specific activations from the hook point (e.g., \"Block 8\") through the SAE.\n",
    "\n",
    "# A function that ignores the incoming activations and blindly returns sae_out (our SAE reconstruction). Used to \"hot-swap\" the brain state.\n",
    "def reconstr_hook(activations, hook, sae_out):\n",
    "    return sae_out # replaced activations with SAE reconstruction\n",
    "\n",
    "# A function that replaces everything with zeros (lobotomy).\n",
    "def zero_abl_hook(mlp_out, hook):\n",
    "    return torch.zeros_like(mlp_out)\n",
    "\n",
    "# The exact address of the layer we are modifying (e.g., 'blocks.8.hook_resid_pre').\n",
    "hook_name = sae.cfg.metadata.hook_name\n",
    "\n",
    "print(\"Orig\", model(tokens, return_type=\"loss\").item())\n",
    "\n",
    "# Calculating the loss when we swap in the SAE reconstruction.\n",
    "# We want to see if the SAE intervention causes the loss to spike for this specific task.\n",
    "print(\n",
    "    \"reconstr\",\n",
    "    model.run_with_hooks(\n",
    "        tokens,\n",
    "        fwd_hooks=[\n",
    "            (\n",
    "                hook_name,\n",
    "                partial(reconstr_hook, sae_out=sae_out),\n",
    "            )\n",
    "        ],\n",
    "        return_type=\"loss\",\n",
    "    ).item(),\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"Zero\",\n",
    "    model.run_with_hooks(\n",
    "        tokens,\n",
    "        return_type=\"loss\",\n",
    "        fwd_hooks=[(hook_name, zero_abl_hook)],\n",
    "    ).item(),\n",
    ")\n",
    "\n",
    "\n",
    "with model.hooks(\n",
    "    fwd_hooks=[\n",
    "        (\n",
    "            hook_name,\n",
    "            partial(reconstr_hook, sae_out=sae_out),\n",
    "        )\n",
    "    ]\n",
    "):\n",
    "    utils.test_prompt(example_prompt, example_answer, model, prepend_bos=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa2b5bb",
   "metadata": {},
   "source": [
    "# Generating Feature Interfaces\n",
    "\n",
    "Feature dashboards are an important part of SAE Evaluation. They work by:\n",
    "\n",
    "- 1. Collecting feature activations over a larger number of examples.\n",
    "- 2. Aggregating feature specific statistics (such as max activating examples).\n",
    "- 3. Representing that information in a standardized way\n",
    "\n",
    "For our feature visualizations, we will use a separate library called SAEDashboard.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37a083c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Forward passes to cache data for vis:  98%|| 39/40 [00:12<00:00,  3.17it/s]/ssd/jdh/interpretability/experiments/exp-sae-lens/.venv/lib/python3.10/site-packages/eindex/indexing.py:288: UserWarning:\n",
      "\n",
      "Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
      "\n",
      "/ssd/jdh/interpretability/experiments/exp-sae-lens/.venv/lib/python3.10/site-packages/eindex/indexing.py:292: UserWarning:\n",
      "\n",
      "Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
      "\n",
      "/ssd/jdh/interpretability/experiments/exp-sae-lens/.venv/lib/python3.10/site-packages/eindex/indexing.py:296: UserWarning:\n",
      "\n",
      "Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Task </span><span style=\"font-weight: bold\"> Time </span><span style=\"font-weight: bold\"> Pct % </span>\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mTask\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mTime\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mPct %\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Forward passes to cache data for vis: 100%|| 40/40 [00:12<00:00,  3.19it/s]\n",
      "Extracting vis data from cached data: 100%|| 11/11 [00:12<00:00,  1.14s/it]\n"
     ]
    }
   ],
   "source": [
    "# Make sure to install sae-dashboard if not running in colab\n",
    "# pip install sae-dashboard\n",
    "# Note: this cell may not work until sae-dashboard is updated to work with the latest version of sae-lens\n",
    "\n",
    "test_feature_idx_gpt = list(range(10)) + [14057] # first ten features + one random feature\n",
    "\n",
    "from sae_dashboard.sae_vis_data import SaeVisConfig\n",
    "from sae_dashboard.sae_vis_runner import SaeVisRunner\n",
    "\n",
    "\n",
    "feature_vis_config_gpt = SaeVisConfig(\n",
    "    hook_point=hook_name,\n",
    "    features=test_feature_idx_gpt,\n",
    "    minibatch_size_features=64,\n",
    "    minibatch_size_tokens=256,\n",
    "    verbose=True,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "# Collect activation stats for selected SAE features on a token sample for dashboard plots.\n",
    "visualization_data_gpt = SaeVisRunner(\n",
    "    feature_vis_config_gpt\n",
    ").run(\n",
    "    encoder=sae,  # type: ignore\n",
    "    model=model,\n",
    "    tokens=token_dataset[:10000][\"tokens\"],  # type: ignore\n",
    ")\n",
    "# SaeVisData.create(\n",
    "#     encoder=sae,\n",
    "#     model=model, # type: ignore\n",
    "#     tokens=token_dataset[:10000][\"tokens\"],  # type: ignore\n",
    "#     cfg=feature_vis_config_gpt,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1bdfc21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving feature-centric vis:   0%|          | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving feature-centric vis: 100%|| 11/11 [00:00<00:00, 35.44it/s]\n"
     ]
    }
   ],
   "source": [
    "from sae_dashboard.data_writing_fns import save_feature_centric_vis\n",
    "\n",
    "filename = f\"demo_feature_dashboards.html\"\n",
    "save_feature_centric_vis(sae_vis_data=visualization_data_gpt, filename=filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52ecd045",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sae_lens.analysis.neuronpedia_integration import get_neuronpedia_quick_list\n",
    "\n",
    "# this function should open\n",
    "neuronpedia_quick_list = get_neuronpedia_quick_list(sae, test_feature_idx_gpt)\n",
    "\n",
    "if COLAB:\n",
    "    # If you're on colab, click the link below\n",
    "    print(neuronpedia_quick_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exp-sae-lens",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
