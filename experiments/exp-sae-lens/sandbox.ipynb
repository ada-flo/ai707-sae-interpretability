{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35b20600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b48ad7e3ce534b56bf4846a79f91636a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "cfg.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7e7802c759d45ae8d0fd36833fcf924",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "blocks.8.hook_resid_pre/sae_weights.safe(…):   0%|          | 0.00/151M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59be2f171f6f4dabaca36dead10138ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "blocks.8.hook_resid_pre/sparsity.safeten(…):   0%|          | 0.00/98.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msae_lens\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SAE\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m sae = \u001b[43mSAE\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrelease\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt2-small-res-jb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# see other options in sae_lens/pretrained_saes.yaml\u001b[39;49;00m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43msae_id\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mblocks.8.hook_resid_pre\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# won't always be a hook point\u001b[39;49;00m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/2025-2/AI707/interpretability/experiments/sae-lens/.venv/lib/python3.12/site-packages/sae_lens/saes/sae.py:567\u001b[39m, in \u001b[36mSAE.from_pretrained\u001b[39m\u001b[34m(cls, release, sae_id, device, force_download, converter)\u001b[39m\n\u001b[32m    550\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    551\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_pretrained\u001b[39m(\n\u001b[32m    552\u001b[39m     \u001b[38;5;28mcls\u001b[39m: \u001b[38;5;28mtype\u001b[39m[T_SAE],\n\u001b[32m   (...)\u001b[39m\u001b[32m    557\u001b[39m     converter: PretrainedSaeHuggingfaceLoader | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    558\u001b[39m ) -> T_SAE:\n\u001b[32m    559\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    560\u001b[39m \u001b[33;03m    Load a pretrained SAE from the Hugging Face model hub.\u001b[39;00m\n\u001b[32m    561\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    565\u001b[39m \u001b[33;03m        device: The device to load the SAE on.\u001b[39;00m\n\u001b[32m    566\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m567\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained_with_cfg_and_sparsity\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    568\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrelease\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msae_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconverter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconverter\u001b[49m\n\u001b[32m    569\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/2025-2/AI707/interpretability/experiments/sae-lens/.venv/lib/python3.12/site-packages/sae_lens/saes/sae.py:639\u001b[39m, in \u001b[36mSAE.from_pretrained_with_cfg_and_sparsity\u001b[39m\u001b[34m(cls, release, sae_id, device, force_download, converter)\u001b[39m\n\u001b[32m    636\u001b[39m config_overrides[\u001b[33m\"\u001b[39m\u001b[33mdevice\u001b[39m\u001b[33m\"\u001b[39m] = device\n\u001b[32m    638\u001b[39m \u001b[38;5;66;03m# Load config and weights\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m639\u001b[39m cfg_dict, state_dict, log_sparsities = \u001b[43mconversion_loader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    640\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    641\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfolder_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfolder_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    642\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    643\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    644\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcfg_overrides\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig_overrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    646\u001b[39m cfg_dict = handle_config_defaulting(cfg_dict)\n\u001b[32m    648\u001b[39m \u001b[38;5;66;03m# Create SAE with appropriate architecture\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/2025-2/AI707/interpretability/experiments/sae-lens/.venv/lib/python3.12/site-packages/sae_lens/loading/pretrained_sae_loaders.py:122\u001b[39m, in \u001b[36msae_lens_huggingface_loader\u001b[39m\u001b[34m(repo_id, folder_name, device, force_download, cfg_overrides)\u001b[39m\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError:\n\u001b[32m    120\u001b[39m     log_sparsity_path = \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# no sparsity file\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m cfg_dict, state_dict = \u001b[43mread_sae_components_from_disk\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcfg_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43msae_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[38;5;66;03m# get sparsity tensor if it exists\u001b[39;00m\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m log_sparsity_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/2025-2/AI707/interpretability/experiments/sae-lens/.venv/lib/python3.12/site-packages/sae_lens/loading/pretrained_sae_loaders.py:347\u001b[39m, in \u001b[36mread_sae_components_from_disk\u001b[39m\u001b[34m(cfg_dict, weight_path, device, dtype)\u001b[39m\n\u001b[32m    345\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m safe_open(weight_path, framework=\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m, device=device) \u001b[38;5;28;01mas\u001b[39;00m f:  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    346\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m f.keys():  \u001b[38;5;66;03m# noqa: SIM118\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m         state_dict[k] = \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m.to(dtype=dtype)\n\u001b[32m    349\u001b[39m \u001b[38;5;66;03m# if bool and True, then it's the April update method of normalizing activations and hasn't been folded in.\u001b[39;00m\n\u001b[32m    350\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mscaling_factor\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m state_dict:\n\u001b[32m    351\u001b[39m     \u001b[38;5;66;03m# we were adding it anyway for a period of time but are no longer doing so.\u001b[39;00m\n\u001b[32m    352\u001b[39m     \u001b[38;5;66;03m# so we should delete it if\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/2025-2/AI707/interpretability/experiments/sae-lens/.venv/lib/python3.12/site-packages/torch/cuda/__init__.py:403\u001b[39m, in \u001b[36m_lazy_init\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    398\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    399\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    400\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmultiprocessing, you must use the \u001b[39m\u001b[33m'\u001b[39m\u001b[33mspawn\u001b[39m\u001b[33m'\u001b[39m\u001b[33m start method\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    401\u001b[39m     )\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch._C, \u001b[33m\"\u001b[39m\u001b[33m_cuda_getDeviceCount\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m403\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mTorch not compiled with CUDA enabled\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    404\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    405\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[32m    406\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    407\u001b[39m     )\n",
      "\u001b[31mAssertionError\u001b[39m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "from sae_lens import SAE\n",
    "\n",
    "sae = SAE.from_pretrained(\n",
    "    release = \"gpt2-small-res-jb\", # see other options in sae_lens/pretrained_saes.yaml\n",
    "    sae_id = \"blocks.8.hook_resid_pre\", # won't always be a hook point\n",
    "    device = \"cuda\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f1465f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4caf0963",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
